{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b59991c",
   "metadata": {},
   "source": [
    "# Test 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de747e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "lib_decomren = \"/home/dotamthuc-3090/Projects/ViewSynthesis/DeConRen\"\n",
    "sys.path.insert(0, lib_decomren)\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import decompress_render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969bf1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  1],\n",
       "       [ 0,  1,  0,  2],\n",
       "       [ 0,  1,  1,  3],\n",
       "       [ 1,  0,  0,  4],\n",
       "       [ 1,  0,  1,  5],\n",
       "       [ 1,  1,  0,  6],\n",
       "       [ 1,  1,  1,  7],\n",
       "       [ 0,  0,  2,  8],\n",
       "       [ 0,  0,  3,  9],\n",
       "       [ 0,  1,  2, 10],\n",
       "       [ 0,  1,  3, 11],\n",
       "       [ 1,  0,  2, 12],\n",
       "       [ 1,  0,  3, 13],\n",
       "       [ 1,  1,  2, 14],\n",
       "       [ 1,  1,  3, 15],\n",
       "       [ 0,  2,  0, 16],\n",
       "       [ 0,  2,  1, 17],\n",
       "       [ 0,  3,  0, 18],\n",
       "       [ 0,  3,  1, 19],\n",
       "       [ 1,  2,  0, 20],\n",
       "       [ 1,  2,  1, 21],\n",
       "       [ 1,  3,  0, 22],\n",
       "       [ 1,  3,  1, 23],\n",
       "       [ 0,  2,  2, 24],\n",
       "       [ 0,  2,  3, 25],\n",
       "       [ 0,  3,  2, 26],\n",
       "       [ 0,  3,  3, 27],\n",
       "       [ 1,  2,  2, 28],\n",
       "       [ 1,  2,  3, 29],\n",
       "       [ 1,  3,  2, 30],\n",
       "       [ 1,  3,  3, 31],\n",
       "       [ 2,  0,  0, 32],\n",
       "       [ 2,  0,  1, 33],\n",
       "       [ 2,  1,  0, 34],\n",
       "       [ 2,  1,  1, 35],\n",
       "       [ 3,  0,  0, 36],\n",
       "       [ 3,  0,  1, 37],\n",
       "       [ 3,  1,  0, 38],\n",
       "       [ 3,  1,  1, 39],\n",
       "       [ 2,  0,  2, 40],\n",
       "       [ 2,  0,  3, 41],\n",
       "       [ 2,  1,  2, 42],\n",
       "       [ 2,  1,  3, 43],\n",
       "       [ 3,  0,  2, 44],\n",
       "       [ 3,  0,  3, 45],\n",
       "       [ 3,  1,  2, 46],\n",
       "       [ 3,  1,  3, 47],\n",
       "       [ 2,  2,  0, 48],\n",
       "       [ 2,  2,  1, 49],\n",
       "       [ 2,  3,  0, 50],\n",
       "       [ 2,  3,  1, 51],\n",
       "       [ 3,  2,  0, 52],\n",
       "       [ 3,  2,  1, 53],\n",
       "       [ 3,  3,  0, 54],\n",
       "       [ 3,  3,  1, 55],\n",
       "       [ 2,  2,  2, 56],\n",
       "       [ 2,  2,  3, 57],\n",
       "       [ 2,  3,  2, 58],\n",
       "       [ 2,  3,  3, 59],\n",
       "       [ 3,  2,  2, 60],\n",
       "       [ 3,  2,  3, 61],\n",
       "       [ 3,  3,  2, 62],\n",
       "       [ 3,  3,  3, 63]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_np = np.array(tuple(itertools.product([0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3])))\n",
    "pos = torch.tensor(pos_np, dtype=torch.int64).cuda()\n",
    "nlevel = torch.tensor([2], dtype=torch.int8).cuda()\n",
    "morton_code = decompress_render.utils.position_to_mortoncode(pos, nlevel).cpu().numpy()\n",
    "combi = np.concatenate([pos_np, morton_code], axis=1)[np.argsort(morton_code[:, 0])]\n",
    "\n",
    "combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b12c733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 1],\n",
       "        [0, 0, 2],\n",
       "        [0, 0, 3],\n",
       "        [0, 1, 2],\n",
       "        [0, 1, 3],\n",
       "        [1, 0, 2],\n",
       "        [1, 0, 3],\n",
       "        [1, 1, 2],\n",
       "        [1, 1, 3],\n",
       "        [0, 2, 0],\n",
       "        [0, 2, 1],\n",
       "        [0, 3, 0],\n",
       "        [0, 3, 1],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 3, 0],\n",
       "        [1, 3, 1],\n",
       "        [0, 2, 2],\n",
       "        [0, 2, 3],\n",
       "        [0, 3, 2],\n",
       "        [0, 3, 3],\n",
       "        [1, 2, 2],\n",
       "        [1, 2, 3],\n",
       "        [1, 3, 2],\n",
       "        [1, 3, 3],\n",
       "        [2, 0, 0],\n",
       "        [2, 0, 1],\n",
       "        [2, 1, 0],\n",
       "        [2, 1, 1],\n",
       "        [3, 0, 0],\n",
       "        [3, 0, 1],\n",
       "        [3, 1, 0],\n",
       "        [3, 1, 1],\n",
       "        [2, 0, 2],\n",
       "        [2, 0, 3],\n",
       "        [2, 1, 2],\n",
       "        [2, 1, 3],\n",
       "        [3, 0, 2],\n",
       "        [3, 0, 3],\n",
       "        [3, 1, 2],\n",
       "        [3, 1, 3],\n",
       "        [2, 2, 0],\n",
       "        [2, 2, 1],\n",
       "        [2, 3, 0],\n",
       "        [2, 3, 1],\n",
       "        [3, 2, 0],\n",
       "        [3, 2, 1],\n",
       "        [3, 3, 0],\n",
       "        [3, 3, 1],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 3],\n",
       "        [2, 3, 2],\n",
       "        [2, 3, 3],\n",
       "        [3, 2, 2],\n",
       "        [3, 2, 3],\n",
       "        [3, 3, 2],\n",
       "        [3, 3, 3]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nlevel = torch.ones((2), dtype=torch.int8).cuda()\n",
    "decompress_render.utils.mortoncode_to_position(torch.tensor(combi[:, 3], dtype=torch.int64).cuda(), nlevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81cee4e",
   "metadata": {},
   "source": [
    "# Test 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129e2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "lib_decomren = \"/home/dotamthuc-3090/Projects/ViewSynthesis/DeConRen\"\n",
    "sys.path.insert(0, lib_decomren)\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import decompress_render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d04c4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lookat_to_colmap_quaternion(eye, lookat, up=np.array([0.0, -1.0, 0.0])):\n",
    "    \"\"\"\n",
    "    Convert eye + lookat + up → COLMAP quaternion (w, x, y, z) and translation (t_x, t_y, t_z)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eye     : array-like (3,)   → camera position in world (e.g. [2, 3, 4])\n",
    "    lookat  : array-like (3,)   → point the camera is looking at\n",
    "    up      : array-like (3,)   → up direction (default = OpenGL/Blender style: Y down)\n",
    "              Use [0,1,0] if your world has +Y up (like most COLMAP datasets)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    qvec    : np.array (4,)     → [qw, qx, qy, qz]  (COLMAP order, unit quaternion)\n",
    "    tvec    : np.array (3,)     → translation that COLMAP expects (world → camera)\n",
    "    R       : np.array (3,3)    → rotation matrix (world → camera)  [optional bonus]\n",
    "    \"\"\"\n",
    "    eye    = np.asarray(eye,    dtype=np.float64)\n",
    "    lookat = np.asarray(lookat, dtype=np.float64)\n",
    "    up     = np.asarray(up,     dtype=np.float64)\n",
    "\n",
    "    # Forward vector (from camera to target)\n",
    "    forward = lookat - eye\n",
    "    forward = forward / np.linalg.norm(forward)\n",
    "\n",
    "    # Right vector\n",
    "    right = np.cross(forward, up)\n",
    "    right = right / np.linalg.norm(right)\n",
    "\n",
    "    # Recompute up to be orthogonal (Gram-Schmidt)\n",
    "    up_clean = np.cross(right, forward)   # note: forward × right would be wrong order\n",
    "\n",
    "    # Build rotation matrix (world → camera)\n",
    "    # Each column is a basis vector of the camera frame expressed in world\n",
    "    R = np.stack((right, -up_clean, -forward), axis=1)   # note the signs!\n",
    "    # Explanation of signs:\n",
    "    #   +Xcam → right\n",
    "    #   +Ycam → down (if up was [0,-1,0]) → we want -up_clean\n",
    "    #   +Zcam → backward (opposite of forward)\n",
    "\n",
    "    # Convert rotation matrix → quaternion (scalar-first!)\n",
    "    # Using the most numerically stable method\n",
    "    trace = R[0,0] + R[1,1] + R[2,2]\n",
    "    \n",
    "    if trace > 0:\n",
    "        s = 0.5 / np.sqrt(trace + 1.0)\n",
    "        w = 0.25 / s\n",
    "        x = (R[2,1] - R[1,2]) * s\n",
    "        y = (R[0,2] - R[2,0]) * s\n",
    "        z = (R[1,0] - R[0,1]) * s\n",
    "    else:\n",
    "        if R[0,0] > R[1,1] and R[0,0] > R[2,2]:\n",
    "            s = 2.0 * np.sqrt(1.0 + R[0,0] - R[1,1] - R[2,2])\n",
    "            w = (R[2,1] - R[1,2]) / s\n",
    "            x = 0.25 * s\n",
    "            y = (R[0,1] + R[1,0]) / s\n",
    "            z = (R[0,2] + R[2,0]) / s\n",
    "        elif R[1,1] > R[2,2]:\n",
    "            s = 2.0 * np.sqrt(1.0 + R[1,1] - R[0,0] - R[2,2])\n",
    "            w = (R[0,2] - R[2,0]) / s\n",
    "            x = (R[0,1] + R[1,0]) / s\n",
    "            y = 0.25 * s\n",
    "            z = (R[1,2] + R[2,1]) / s\n",
    "        else:\n",
    "            s = 2.0 * np.sqrt(1.0 + R[2,2] - R[0,0] - R[1,1])\n",
    "            w = (R[1,0] - R[0,1]) / s\n",
    "            x = (R[0,2] + R[2,0]) / s\n",
    "            y = (R[1,2] + R[2,1]) / s\n",
    "            z = 0.25 * s\n",
    "\n",
    "    qvec = np.array([w, x, y, z])\n",
    "    \n",
    "    # COLMAP translation (world → camera): t = -R @ eye\n",
    "    tvec = -R @ eye\n",
    "\n",
    "    return qvec, tvec, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98a0fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qvec2rotmat(qvec):\n",
    "    \"\"\"Convert COLMAP qvec (w, x, y, z) to 3x3 rotation matrix\"\"\"\n",
    "    w, x, y, z = qvec\n",
    "    return np.array([\n",
    "        [1 - 2*y*y - 2*z*z,  2*x*y - 2*z*w,      2*x*z + 2*y*w],\n",
    "        [2*x*y + 2*z*w,      1 - 2*x*x - 2*z*z,  2*y*z - 2*x*w],\n",
    "        [2*x*z - 2*y*w,      2*y*z + 2*x*w,      1 - 2*x*x - 2*y*y]\n",
    "    ])\n",
    "\n",
    "def colmap_pose_to_camera_to_world(qvec, tvec):\n",
    "    \"\"\"\n",
    "    Input: qvec (4,), tvec (3,) from images.txt\n",
    "    Output: 4x4 camera-to-world matrix (numpy array)\n",
    "    \"\"\"\n",
    "    R = qvec2rotmat(qvec)           # world → cam rotation\n",
    "    t = tvec.reshape(3, 1)           # world → cam translation\n",
    "    \n",
    "    # Camera-to-world = [R^T | -R^T t]\n",
    "    cam_to_world = np.eye(4)\n",
    "    cam_to_world[:3, :3] = R.T\n",
    "    cam_to_world[:3, [3]]   = -R.T @ t\n",
    "    return cam_to_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f0834f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qvec: [ 0.699428 -0.040193  0.132748  0.050999]\n",
      "tvec: [-1.9136   -0.735151 -4.979728]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.95955428,  0.06066858, -0.18979489,  0.93567716],\n",
       "       [-0.08201065,  0.99156737, -0.04268413,  0.35946046],\n",
       "       [ 0.18159579,  0.06976392,  0.96152505,  5.18692157],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: Camera looking down -Z axis (common in many datasets)\n",
    "eye    = [0.0, 0.0, 0.0]\n",
    "lookat = [1.0, 1.0, 1.0]\n",
    "up     = [0.0, -1.0, 0.0]      # +Y up (standard COLMAP convention)\n",
    "\n",
    "eye    = [2.0, -3.0, 4.0]\n",
    "lookat = [0.0, 0.0, 0.0]\n",
    "up     = [0.0, 0.0, 1.0]\n",
    "\n",
    "q, t, R = lookat_to_colmap_quaternion(eye, lookat, up)\n",
    "print(\"qvec:\", q.round(6))\n",
    "print(\"tvec:\", t.round(6))\n",
    "\n",
    "\n",
    "cam2world = colmap_pose_to_camera_to_world(q, t)\n",
    "cam2world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e24db099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.85355339,  0.5       ,  0.14644661,  0.        ],\n",
       "       [-0.5       ,  0.70710678,  0.5       ,  0.        ],\n",
       "       [ 0.14644661, -0.5       ,  0.85355339,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam2world = colmap_pose_to_camera_to_world(\n",
    "    np.array([0.92387953, 0.38268343/np.sqrt(2),  0.0, 0.38268343/np.sqrt(2)]), \n",
    "    np.array([0.0, 0.0, 0.0])\n",
    ")\n",
    "cam2world\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "36e79ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.5000],\n",
       "         [0.2500, 0.5000, 0.2500],\n",
       "         [0.2500, 0.5000, 0.5000],\n",
       "         [0.5000, 0.2500, 0.2500],\n",
       "         [0.5000, 0.2500, 0.5000],\n",
       "         [0.5000, 0.5000, 0.2500],\n",
       "         [0.5000, 0.5000, 0.5000]], device='cuda:0'),\n",
       " tensor([0.2500], device='cuda:0'))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nlevel = torch.tensor([2], dtype=torch.int8).cuda()\n",
    "vox_roots = torch.tensor(tuple(itertools.product([1, 2], [1, 2], [1, 2])), dtype=torch.float32).cuda() * 2**(-2)\n",
    "vox_len = torch.ldexp(torch.tensor([1], dtype=torch.int8).cuda(), -nlevel)\n",
    "vox_roots, vox_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d7a77aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "camera_settings = decompress_render.renderer.CameraSettings(\n",
    "    image_width=256, \n",
    "    image_height=256, \n",
    "    tanfovx=1.0, \n",
    "    tanfovy=1.0, \n",
    "    cx=128.0, \n",
    "    cy=128.0, \n",
    "    w2c_matrix=torch.tensor([cam2world], dtype=torch.float32).clone().cuda().inverse(),\n",
    "    c2w_matrix=torch.tensor([cam2world], dtype=torch.float32).clone().cuda()\n",
    ")\n",
    "render_settings = decompress_render.renderer.RenderSettings(\n",
    "    num_sample_per_vox=3,\n",
    "    bg_color=3,\n",
    "    near=0.001,\n",
    "    need_depth=False,\n",
    "    track_max_w=False,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9c4ef936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.8536,  0.5000,  0.1464,  0.0000],\n",
       "          [-0.5000,  0.7071,  0.5000,  0.0000],\n",
       "          [ 0.1464, -0.5000,  0.8536,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0'),\n",
       " tensor([[[ 0.8536, -0.5000,  0.1464,  0.0000],\n",
       "          [ 0.5000,  0.7071, -0.5000,  0.0000],\n",
       "          [ 0.1464,  0.5000,  0.8536,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0'))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_settings.c2w_matrix, camera_settings.w2c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a7be34c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2500e-01,  1.7678e-01,  3.7500e-01],\n",
       "         [ 1.6161e-01,  5.1777e-02,  5.8839e-01],\n",
       "         [-1.4901e-08,  3.5355e-01,  5.0000e-01],\n",
       "         [ 3.6612e-02,  2.2855e-01,  7.1339e-01],\n",
       "         [ 3.3839e-01,  3.0178e-01,  4.1161e-01],\n",
       "         [ 3.7500e-01,  1.7678e-01,  6.2500e-01],\n",
       "         [ 2.1339e-01,  4.7855e-01,  5.3661e-01],\n",
       "         [ 2.5000e-01,  3.5355e-01,  7.5000e-01]], device='cuda:0'),\n",
       " tensor([[ 3.3333e-01,  4.7140e-01],\n",
       "         [ 2.7467e-01,  8.7998e-02],\n",
       "         [-2.9802e-08,  7.0711e-01],\n",
       "         [ 5.1321e-02,  3.2038e-01],\n",
       "         [ 8.2211e-01,  7.3316e-01],\n",
       "         [ 6.0000e-01,  2.8284e-01],\n",
       "         [ 3.9766e-01,  8.9181e-01],\n",
       "         [ 3.3333e-01,  4.7140e-01]], device='cuda:0'))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = (camera_settings.w2c_matrix[0, :3, :3, ] @ vox_roots.T).T\n",
    "temp, temp[:, :2]/temp[:, [2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e196942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c3c5b0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 8 \n",
      "chunk_size: 1407 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([64, 25, 36, 20, 36, 30, 25, 20], device='cuda:0', dtype=torch.int32),\n",
       " tensor([64,  0,  0,  ...,  0,  0,  0], device='cuda:0', dtype=torch.uint8),\n",
       " tensor([127.5000, 138.7637, 232.7295, 241.6512, 134.0691, 115.8102, 204.3000,\n",
       "         187.8398, 101.9000, 168.5083, 178.4003, 254.2847, 114.0054, 141.8021,\n",
       "         170.1667, 205.0797, 170.1667, 163.7039, 256.0000, 256.0000, 165.5805,\n",
       "         135.4050, 241.3337, 205.3718, 144.6002, 187.8398, 222.7986, 256.0000,\n",
       "         145.7857, 157.8666, 202.9041, 219.5153], device='cuda:0'))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c = decompress_render.renderer.rasterize_voxels(\n",
    "    camera_settings, render_settings,\n",
    "    vox_roots,\n",
    "    vox_len,\n",
    "    lambda x: None\n",
    ")\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bba27a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([64, 25, 36, 20, 36, 30, 25, 20], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7e98e9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.5000],\n",
       "         [0.2500, 0.5000, 0.2500],\n",
       "         [0.2500, 0.5000, 0.5000],\n",
       "         [0.5000, 0.2500, 0.2500],\n",
       "         [0.5000, 0.2500, 0.5000],\n",
       "         [0.5000, 0.5000, 0.2500],\n",
       "         [0.5000, 0.5000, 0.5000]], device='cuda:0'),\n",
       " tensor([[[127, 138],\n",
       "          [232, 241]],\n",
       " \n",
       "         [[134, 115],\n",
       "          [204, 187]],\n",
       " \n",
       "         [[101, 168],\n",
       "          [178, 254]],\n",
       " \n",
       "         [[114, 141],\n",
       "          [170, 205]],\n",
       " \n",
       "         [[170, 163],\n",
       "          [256, 256]],\n",
       " \n",
       "         [[165, 135],\n",
       "          [241, 205]],\n",
       " \n",
       "         [[144, 187],\n",
       "          [222, 256]],\n",
       " \n",
       "         [[145, 157],\n",
       "          [202, 219]]], device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vox_roots, c.reshape((8, 2, 2)).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b5f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54b8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eead47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000, -0.0000],\n",
       "         [-0.3062,  0.1768],\n",
       "         [-0.0000, -0.3536],\n",
       "         [-0.2449, -0.1414],\n",
       "         [ 0.3062,  0.1768],\n",
       "         [-0.0000,  0.2828],\n",
       "         [ 0.2449, -0.1414],\n",
       "         [-0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.3062,  0.1768],\n",
       "         [-0.4899,  0.2828],\n",
       "         [-0.2449, -0.1414],\n",
       "         [-0.4082, -0.0000],\n",
       "         [-0.0000,  0.2828],\n",
       "         [-0.2041,  0.3536],\n",
       "         [-0.0000, -0.0000],\n",
       "         [-0.1750,  0.1010]],\n",
       "\n",
       "        [[-0.0000, -0.3536],\n",
       "         [-0.2449, -0.1414],\n",
       "         [-0.0000, -0.5657],\n",
       "         [-0.2041, -0.3536],\n",
       "         [ 0.2449, -0.1414],\n",
       "         [-0.0000, -0.0000],\n",
       "         [ 0.2041, -0.3536],\n",
       "         [-0.0000, -0.2020]],\n",
       "\n",
       "        [[-0.2449, -0.1414],\n",
       "         [-0.4082, -0.0000],\n",
       "         [-0.2041, -0.3536],\n",
       "         [-0.3499, -0.2020],\n",
       "         [-0.0000, -0.0000],\n",
       "         [-0.1750,  0.1010],\n",
       "         [-0.0000, -0.2020],\n",
       "         [-0.1531, -0.0884]],\n",
       "\n",
       "        [[ 0.3062,  0.1768],\n",
       "         [-0.0000,  0.2828],\n",
       "         [ 0.2449, -0.1414],\n",
       "         [-0.0000, -0.0000],\n",
       "         [ 0.4899,  0.2828],\n",
       "         [ 0.2041,  0.3536],\n",
       "         [ 0.4082, -0.0000],\n",
       "         [ 0.1750,  0.1010]],\n",
       "\n",
       "        [[-0.0000,  0.2828],\n",
       "         [-0.2041,  0.3536],\n",
       "         [-0.0000, -0.0000],\n",
       "         [-0.1750,  0.1010],\n",
       "         [ 0.2041,  0.3536],\n",
       "         [-0.0000,  0.4041],\n",
       "         [ 0.1750,  0.1010],\n",
       "         [-0.0000,  0.1768]],\n",
       "\n",
       "        [[ 0.2449, -0.1414],\n",
       "         [-0.0000, -0.0000],\n",
       "         [ 0.2041, -0.3536],\n",
       "         [-0.0000, -0.2020],\n",
       "         [ 0.4082, -0.0000],\n",
       "         [ 0.1750,  0.1010],\n",
       "         [ 0.3499, -0.2020],\n",
       "         [ 0.1531, -0.0884]],\n",
       "\n",
       "        [[-0.0000, -0.0000],\n",
       "         [-0.1750,  0.1010],\n",
       "         [-0.0000, -0.2020],\n",
       "         [-0.1531, -0.0884],\n",
       "         [ 0.1750,  0.1010],\n",
       "         [-0.0000,  0.1768],\n",
       "         [ 0.1531, -0.0884],\n",
       "         [-0.0000, -0.0000]]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_conner = c.reshape((64, 3))\n",
    "cam_conner_scaled = cam_conner[:, :2] / cam_conner[:, [2]]\n",
    "cam_conner_scaled = cam_conner_scaled.reshape((8, 8, 2))\n",
    "cam_conner_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b60c3338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.5000],\n",
       "         [0.2500, 0.5000, 0.2500],\n",
       "         [0.2500, 0.5000, 0.5000],\n",
       "         [0.5000, 0.2500, 0.2500],\n",
       "         [0.5000, 0.2500, 0.5000],\n",
       "         [0.5000, 0.5000, 0.2500],\n",
       "         [0.5000, 0.5000, 0.5000]], device='cuda:0'),\n",
       " tensor([[-0.3062, -0.3536],\n",
       "         [-0.4899, -0.1414],\n",
       "         [-0.2449, -0.5657],\n",
       "         [-0.4082, -0.3536],\n",
       "         [-0.0000, -0.1414],\n",
       "         [-0.2041, -0.0000],\n",
       "         [-0.0000, -0.3536],\n",
       "         [-0.1750, -0.2020]], device='cuda:0'),\n",
       " tensor([[0.3062, 0.2828],\n",
       "         [-0.0000, 0.3536],\n",
       "         [0.2449, -0.0000],\n",
       "         [-0.0000, 0.1010],\n",
       "         [0.4899, 0.3536],\n",
       "         [0.2041, 0.4041],\n",
       "         [0.4082, 0.1010],\n",
       "         [0.1750, 0.1768]], device='cuda:0'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vox_roots, cam_conner_scaled.min(axis=1)[0], cam_conner_scaled.max(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0f9808b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_conner_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SH colors\n",
    "# SH_C0 = 0.28209479177387814\n",
    "# SH_C1 = 0.4886025119029199\n",
    "# SH_C2 = [ 1.0925, -1.0925, 0.3153, -1.0925, 0.5462 ]\n",
    "# SH_C3= [ -0.5900, 2.8906, -0.4570, 0.3731, -0.4570, 1.4453, -0.5900]\n",
    "\n",
    "# # \n",
    "# def computeColorFromSH( vox_center, cam_center, sh0, sh, degree=3):\n",
    "#     # vox_center, cam_center: array of 3D position - [x, y, z]\n",
    "#     # sh0: [cR, cG, cB]\n",
    "#     # sh: array (num_SH_coefs-1) x 3\n",
    "    \n",
    "#     # Normalized ray direction\n",
    "#     dir = vox_center - cam_center\n",
    "#     dir = dir * 1 / (dir[0]**2, dir[1]**2, dir[2]**2)\n",
    "\n",
    "#     # Result is vector 3: [R, G, B]\n",
    "#     result = SH_C0 * sh0\n",
    "\n",
    "#     if (degree > 0):\n",
    "#         x = dir[0]\n",
    "#         y = dir[1]\n",
    "#         z = dir[2]\n",
    "#         result = result - SH_C1 * y * sh[0] + SH_C1 * z * sh[1] - SH_C1 * x * sh[2]\n",
    "\n",
    "#         if (degree > 1):\n",
    "#             xx = x * x\n",
    "#             yy = y * y\n",
    "#             zz = z * z\n",
    "#             xy = x * y\n",
    "#             yz = y * z\n",
    "#             xz = x * z\n",
    "\n",
    "#             result = result + \\\n",
    "#                 SH_C2[0] * xy * sh[3] + \\\n",
    "#                 SH_C2[1] * yz * sh[4] + \\\n",
    "#                 SH_C2[2] * (2.0 * zz - xx - yy) * sh[5] + \\\n",
    "#                 SH_C2[3] * xz * sh[6] + \\\n",
    "#                 SH_C2[4] * (xx - yy) * sh[7]\n",
    "\n",
    "#             if (degree > 2):\n",
    "#                 result = result + \\\n",
    "#                     SH_C3[0] * y * (3.0 * xx - yy) * sh[8] + \\\n",
    "#                     SH_C3[1] * xy * z * sh[9] + \\\n",
    "#                     SH_C3[2] * y * (4.0 * zz - xx - yy) * sh[10] + \\\n",
    "#                     SH_C3[3] * z * (2.0 * zz - 3.0 * xx - 3.0 * yy) * sh[11] + \\\n",
    "#                     SH_C3[4] * x * (4.0 * zz - xx - yy) * sh[12] + \\\n",
    "#                     SH_C3[5] * z * (xx - yy) * sh[13] + \\\n",
    "#                     SH_C3[6] * x * (xx - 3.0 * yy) * sh[14]\n",
    "        \n",
    "#     result = result + 0.5\n",
    "\n",
    "#     # RGB colors are clamped to non-negative values.\n",
    "#     result[0] *= (result[0] > 0.0)\n",
    "#     result[1] *= (result[1] > 0.0)\n",
    "#     result[2] *= (result[2] > 0.0)\n",
    "#     return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5016a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25bb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewSyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
